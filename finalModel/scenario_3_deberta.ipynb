{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ilsilfverskiold/smaller-models-docs/blob/main/nlp/cook/fine-tune/albert_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CZrl7EHuJUfG"
   },
   "source": [
    "# Text Classification with Transformers (ALBERT)\n",
    "\n",
    "This script helps you fine-tune a pre-trained model (ALBERT) and encoder model for text classification with a dataset from the HuggingFace.\n",
    "\n",
    "The use case uses binary classes to produce a model to identify clickbait versus factual content with the use of a synthetic dataset found [here](https://huggingface.co/datasets/ilsilfverskiold/clickbait_titles_synthetic_data). This script follows a tutorial that you can find here.\n",
    "\n",
    "You may use any encoder model such as BERT, RoBERTa and DeBERTa instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvzGqWjSW2sd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -U datasets\n",
    "!pip install -U accelerate\n",
    "!pip install -U transformers\n",
    "!pip install -U huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:59:26.203036Z",
     "iopub.status.busy": "2024-08-05T18:59:26.202702Z",
     "iopub.status.idle": "2024-08-05T18:59:29.355428Z",
     "shell.execute_reply": "2024-08-05T18:59:29.353994Z",
     "shell.execute_reply.started": "2024-08-05T18:59:26.203019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting protobuf\n",
      "  Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Downloading protobuf-5.27.3-cp38-abi3-manylinux2014_x86_64.whl (309 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.3/309.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: protobuf\n",
      "Successfully installed protobuf-5.27.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install protobuf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TB6zvHZFJFMJ"
   },
   "source": [
    "Import the dataset you'll be trainin on. This dataset has a 'text' field and a 'label' field. Be sure to tweak the script if you need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:04.681128Z",
     "iopub.status.busy": "2024-08-05T18:51:04.680780Z",
     "iopub.status.idle": "2024-08-05T18:51:05.101824Z",
     "shell.execute_reply": "2024-08-05T18:51:05.101175Z",
     "shell.execute_reply.started": "2024-08-05T18:51:04.681097Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:06.969239Z",
     "iopub.status.busy": "2024-08-05T18:51:06.968838Z",
     "iopub.status.idle": "2024-08-05T18:51:07.068613Z",
     "shell.execute_reply": "2024-08-05T18:51:07.068039Z",
     "shell.execute_reply.started": "2024-08-05T18:51:06.969221Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cpl.org.pe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>faithandreason.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kimhauser.ch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the national association for honesty in medici...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lokoml.cz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0                                         cpl.org.pe      0\n",
       "1                                 faithandreason.com      0\n",
       "2                                       kimhauser.ch      0\n",
       "3  the national association for honesty in medici...      1\n",
       "4                                          lokoml.cz      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "set_1_df = pd.read_csv('set_1_df.csv')  # Adjust the file path as needed\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "set_1_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:08.885791Z",
     "iopub.status.busy": "2024-08-05T18:51:08.885455Z",
     "iopub.status.idle": "2024-08-05T18:51:08.916983Z",
     "shell.execute_reply": "2024-08-05T18:51:08.916290Z",
     "shell.execute_reply.started": "2024-08-05T18:51:08.885773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CommentaryIt is time to refinance!Your credit ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://unigeol.quip.com/2JtcASZCsaZa/CLICK-HE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>canada update the following commercial have si...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eselworkshop.com</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>california update 3 / 27 / 01 executive summar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  CommentaryIt is time to refinance!Your credit ...      1\n",
       "1  https://unigeol.quip.com/2JtcASZCsaZa/CLICK-HE...      1\n",
       "2  canada update the following commercial have si...      0\n",
       "3                                   eselworkshop.com      0\n",
       "4  california update 3 / 27 / 01 executive summar...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "set_2_df = pd.read_csv('set_2_df.csv')  # Adjust the file path as needed\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "set_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:13.414400Z",
     "iopub.status.busy": "2024-08-05T18:51:13.413965Z",
     "iopub.status.idle": "2024-08-05T18:51:14.430019Z",
     "shell.execute_reply": "2024-08-05T18:51:14.429374Z",
     "shell.execute_reply.started": "2024-08-05T18:51:13.414375Z"
    },
    "id": "shz4-RFOf41U"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, DatasetDict, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# dataset = load_dataset('json', data_files='df_sampled.json')\n",
    "# dataset = load_dataset(\"ealvaradob/phishing-dataset\", \"combined_reduced\", trust_remote_code=True)\n",
    "\n",
    "# Convert dataset to a pandas DataFrame\n",
    "# df = dataset['train'].to_pandas()\n",
    "\n",
    "# Split the DataFrame into train and test sets\n",
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the train and test DataFrames back to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(set_1_df, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(set_2_df, preserve_index=False)\n",
    "\n",
    "# Combine the train and test Datasets into a DatasetDict\n",
    "dataset_split = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'test': test_dataset\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:16.377651Z",
     "iopub.status.busy": "2024-08-05T18:51:16.377315Z",
     "iopub.status.idle": "2024-08-05T18:51:16.382265Z",
     "shell.execute_reply": "2024-08-05T18:51:16.381539Z",
     "shell.execute_reply.started": "2024-08-05T18:51:16.377635Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 20268\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 5076\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWE97S_2I-tC"
   },
   "source": [
    "Decide on your pre-trained model along with your new model's name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:19.305627Z",
     "iopub.status.busy": "2024-08-05T18:51:19.305132Z",
     "iopub.status.idle": "2024-08-05T18:51:19.309856Z",
     "shell.execute_reply": "2024-08-05T18:51:19.308985Z",
     "shell.execute_reply.started": "2024-08-05T18:51:19.305596Z"
    },
    "id": "GAIpslnnf6O6"
   },
   "outputs": [],
   "source": [
    "model_name = \"microsoft/mdeberta-v3-base\"\n",
    "your_path = 'scenario_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DXTBviEKBia"
   },
   "source": [
    "Look over your distribution of the labels (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:22.723168Z",
     "iopub.status.busy": "2024-08-05T18:51:22.722382Z",
     "iopub.status.idle": "2024-08-05T18:51:22.751575Z",
     "shell.execute_reply": "2024-08-05T18:51:22.750750Z",
     "shell.execute_reply.started": "2024-08-05T18:51:22.723133Z"
    },
    "id": "nOvRUItff915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Label Distribution: Counter({0: 10290, 1: 9978})\n",
      "Test Label Distribution: Counter({1: 2589, 0: 2487})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_label_distribution = Counter(train_dataset['label'])\n",
    "test_label_distribution = Counter(test_dataset['label'])\n",
    "\n",
    "print(\"Training Label Distribution:\", train_label_distribution)\n",
    "print(\"Test Label Distribution:\", test_label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZyWkHH0KIA_"
   },
   "source": [
    "Create a label encoder that converts categorical labels to a standardized numerical format. Labels in their original categorical form (e.g., 'clickbait', 'factual') need to be converted into numerical values so that they can be processed by the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:51:25.723137Z",
     "iopub.status.busy": "2024-08-05T18:51:25.722529Z",
     "iopub.status.idle": "2024-08-05T18:51:30.127506Z",
     "shell.execute_reply": "2024-08-05T18:51:30.126887Z",
     "shell.execute_reply.started": "2024-08-05T18:51:25.723104Z"
    },
    "id": "5PeJ0mwigBQ9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36f20bde51a4ba7963f8263efc8c2c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8272f4d4fc493d97a2a3ef7a433dca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5076 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder.fit(train_dataset['label'])\n",
    "\n",
    "def encode_labels(example):\n",
    "    return {'encoded_label': label_encoder.transform([example['label']])[0]}\n",
    "\n",
    "for split in dataset_split:\n",
    "    dataset_split[split] = dataset_split[split].map(encode_labels, batched=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfKX7el9LEsq"
   },
   "source": [
    "The id2label and label2id mappings in AutoConfig are used to inform the model of the specific label-to-ID mappings so we can get the actual label names rather than the numerical reps when we do inference with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T18:52:03.716846Z",
     "iopub.status.busy": "2024-08-05T18:52:03.715928Z",
     "iopub.status.idle": "2024-08-05T18:52:04.203071Z",
     "shell.execute_reply": "2024-08-05T18:52:04.202372Z",
     "shell.execute_reply.started": "2024-08-05T18:52:03.716829Z"
    },
    "id": "_ECd3GJNgG-g"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcfaa4b796fd4ccbb32d89b5ec7aed9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID to Label Mapping: {0: 'benign', 1: 'phishing'}\n",
      "Label to ID Mapping: {'benign': 0, 'phishing': 1}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "unique_labels = sorted(list(set(dataset_split)))\n",
    "# id2label = {i: label for i, label in enumerate(unique_labels)}\n",
    "# label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "\n",
    "id2label = {0: \"benign\", 1: \"phishing\"}\n",
    "label2id = {\"benign\": 0, \"phishing\": 1}\n",
    "\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.id2label = id2label\n",
    "config.label2id = label2id\n",
    "\n",
    "# Verify the correct labels\n",
    "print(\"ID to Label Mapping:\", config.id2label)\n",
    "print(\"Label to ID Mapping:\", config.label2id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cTrvYVzLkoI"
   },
   "source": [
    "The provided code snippet is responsible for loading a tokenizer and a model from the Hugging Face Transformers library. Here we use ALBERT as a model, you can use AutoTokenizer and AutoModelForSequenceClassification if you want to use another model or it's specified tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:01:43.630128Z",
     "iopub.status.busy": "2024-08-05T19:01:43.629683Z",
     "iopub.status.idle": "2024-08-05T19:02:00.778613Z",
     "shell.execute_reply": "2024-08-05T19:02:00.777954Z",
     "shell.execute_reply.started": "2024-08-05T19:01:43.630111Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b066e1cb5444bac89b1f9ff333f92c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, AutoConfig, DebertaV2ForSequenceClassification\n",
    "\n",
    "# tokenizer = DebertaTokenizer.from_pretrained(\"microsoft/deberta-base\")\n",
    "# tokenizer(\"Hello world\")[\"input_ids\"]\n",
    "\n",
    "# tokenizer(\" Hello world\")[\"input_ids\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = DebertaV2ForSequenceClassification.from_pretrained(model_name, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOghCGAdMdqk"
   },
   "source": [
    "This next function makes sure the text data is properly tokenized and labeled, preparing the dataset for efficient training of the transformer model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:02:54.998209Z",
     "iopub.status.busy": "2024-08-05T19:02:54.997570Z",
     "iopub.status.idle": "2024-08-05T19:02:59.949360Z",
     "shell.execute_reply": "2024-08-05T19:02:59.948806Z",
     "shell.execute_reply.started": "2024-08-05T19:02:54.998189Z"
    },
    "id": "N4VJZjwhg38G"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae28e788a6794c81bb40d65e8935443a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/20268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a4199d9d2d429c8762a5da7ca708f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/5076 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5225494aab82464381d7750e794883f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d364a2c26a54308974ae474c8750706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5076 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_invalid_content(example):\n",
    "    return isinstance(example['text'], str)\n",
    "\n",
    "dataset = dataset_split.filter(filter_invalid_content, batched=False)\n",
    "\n",
    "# def encode_data(batch):\n",
    "#     tokenized_inputs = tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)\n",
    "#     tokenized_inputs[\"labels\"] = batch[\"encoded_label\"]\n",
    "#     return tokenized_inputs\n",
    "\n",
    "# dataset_encoded = dataset.map(encode_data, batched=True)\n",
    "# # dataset_encoded\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding='max_length', truncation=True, max_length=256)\n",
    "\n",
    "# Map the tokenization function to the dataset\n",
    "dataset_encoded = dataset_split.map(tokenize_function, batched=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:04.068412Z",
     "iopub.status.busy": "2024-08-05T19:03:04.068164Z",
     "iopub.status.idle": "2024-08-05T19:03:04.073229Z",
     "shell.execute_reply": "2024-08-05T19:03:04.072447Z",
     "shell.execute_reply.started": "2024-08-05T19:03:04.068396Z"
    },
    "id": "iQb-rRu9g5lT"
   },
   "outputs": [],
   "source": [
    "# Set the format for PyTorch\n",
    "dataset_encoded.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:06.182874Z",
     "iopub.status.busy": "2024-08-05T19:03:06.182214Z",
     "iopub.status.idle": "2024-08-05T19:03:06.188397Z",
     "shell.execute_reply": "2024-08-05T19:03:06.187483Z",
     "shell.execute_reply.started": "2024-08-05T19:03:06.182838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 20268\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', 'encoded_label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 5076\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Print the dataset to check the splits\n",
    "print(dataset_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-G5h1ET3NPLl"
   },
   "source": [
    "The DataCollatorWithPadding ensures that all input sequences in a batch are padded to the same length, using the padding logic defined by the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:34.647370Z",
     "iopub.status.busy": "2024-08-05T19:03:34.646775Z",
     "iopub.status.idle": "2024-08-05T19:03:34.666890Z",
     "shell.execute_reply": "2024-08-05T19:03:34.666096Z",
     "shell.execute_reply.started": "2024-08-05T19:03:34.647339Z"
    },
    "id": "xg6Rb7R-g7A-"
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSctqANNNaAc"
   },
   "source": [
    "Next we'll set up LabelEncoder to encode labels and defines a function to compute per-label accuracy from a confusion matrix, providing label-specific accuracy metrics. I.e. when we train the model we want to see the accuracy metrics per label as well as the average metrics. This is more relevant if you have more than two labels, and one is underperforming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:36.989259Z",
     "iopub.status.busy": "2024-08-05T19:03:36.988643Z",
     "iopub.status.idle": "2024-08-05T19:03:36.997305Z",
     "shell.execute_reply": "2024-08-05T19:03:36.996300Z",
     "shell.execute_reply.started": "2024-08-05T19:03:36.989225Z"
    },
    "id": "zgMLYb57g-Lo"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(unique_labels)\n",
    "\n",
    "def per_label_accuracy(y_true, y_pred, labels):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    correct_predictions = cm.diagonal()\n",
    "    label_totals = cm.sum(axis=1)\n",
    "    per_label_acc = np.divide(correct_predictions, label_totals, out=np.zeros_like(correct_predictions, dtype=float), where=label_totals != 0)\n",
    "    return dict(zip(labels, per_label_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HTeQeL8DN05z"
   },
   "source": [
    "Next we set up our compute metrics. Here I've set up several, but you may reduce them if needed be. You can read more on this metrics [here.](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:42.236068Z",
     "iopub.status.busy": "2024-08-05T19:03:42.235538Z",
     "iopub.status.idle": "2024-08-05T19:03:42.242793Z",
     "shell.execute_reply": "2024-08-05T19:03:42.242068Z",
     "shell.execute_reply.started": "2024-08-05T19:03:42.236043Z"
    },
    "id": "HInT5WReNvTS"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    decoded_labels = label_encoder.inverse_transform(labels)\n",
    "    decoded_preds = label_encoder.inverse_transform(preds)\n",
    "\n",
    "    precision = precision_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    recall = recall_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    f1 = f1_score(decoded_labels, decoded_preds, average='weighted')\n",
    "    acc = accuracy_score(decoded_labels, decoded_preds)\n",
    "\n",
    "    labels_list = list(label_encoder.classes_)\n",
    "    per_label_acc = per_label_accuracy(decoded_labels, decoded_preds, labels_list)\n",
    "\n",
    "    per_label_acc_metrics = {}\n",
    "    for label, accuracy in per_label_acc.items():\n",
    "        label_key = f\"accuracy_label_{label}\"\n",
    "        per_label_acc_metrics[label_key] = accuracy\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        **per_label_acc_metrics\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dv3scyLpORAz"
   },
   "source": [
    "Lastly, we set up our training metrics to train the model. I'm following the paper [\"How to Fine-Tune BERT for Text Classification?\"](https://arxiv.org/abs/1905.05583) on epochs, batch size and learning rate but do play around with it if you want to.\n",
    "\n",
    "When it is in training, be sure to look out for training loss and validation loss. Both should decrease consistently. If validation is increasing consistently you may be overfitting your model and you can try to decrease number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:03:45.417316Z",
     "iopub.status.busy": "2024-08-05T19:03:45.416725Z",
     "iopub.status.idle": "2024-08-05T19:17:43.801832Z",
     "shell.execute_reply": "2024-08-05T19:17:43.800509Z",
     "shell.execute_reply.started": "2024-08-05T19:03:45.417283Z"
    },
    "id": "yx_etZ24hBjt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1899' max='1899' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1899/1899 13:56, Epoch 2/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy Label Test</th>\n",
       "      <th>Accuracy Label Train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.591800</td>\n",
       "      <td>0.540752</td>\n",
       "      <td>0.758668</td>\n",
       "      <td>0.745036</td>\n",
       "      <td>0.820086</td>\n",
       "      <td>0.758668</td>\n",
       "      <td>0.528347</td>\n",
       "      <td>0.979915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.057711</td>\n",
       "      <td>0.984634</td>\n",
       "      <td>0.984635</td>\n",
       "      <td>0.984813</td>\n",
       "      <td>0.984634</td>\n",
       "      <td>0.993969</td>\n",
       "      <td>0.975666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.065681</td>\n",
       "      <td>0.983058</td>\n",
       "      <td>0.983059</td>\n",
       "      <td>0.983413</td>\n",
       "      <td>0.983058</td>\n",
       "      <td>0.996381</td>\n",
       "      <td>0.970259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>0.052318</td>\n",
       "      <td>0.988377</td>\n",
       "      <td>0.988378</td>\n",
       "      <td>0.988521</td>\n",
       "      <td>0.988377</td>\n",
       "      <td>0.996783</td>\n",
       "      <td>0.980301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.047961</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.985613</td>\n",
       "      <td>0.985911</td>\n",
       "      <td>0.985619</td>\n",
       "      <td>0.972658</td>\n",
       "      <td>0.998069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.062442</td>\n",
       "      <td>0.986210</td>\n",
       "      <td>0.986211</td>\n",
       "      <td>0.986488</td>\n",
       "      <td>0.986210</td>\n",
       "      <td>0.997990</td>\n",
       "      <td>0.974894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.018487</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.995865</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.996910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.039800</td>\n",
       "      <td>0.082428</td>\n",
       "      <td>0.982467</td>\n",
       "      <td>0.982468</td>\n",
       "      <td>0.982969</td>\n",
       "      <td>0.982467</td>\n",
       "      <td>0.998392</td>\n",
       "      <td>0.967169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0.993340</td>\n",
       "      <td>0.993302</td>\n",
       "      <td>0.997587</td>\n",
       "      <td>0.989185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.021316</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.994687</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.996381</td>\n",
       "      <td>0.993048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.023848</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.993104</td>\n",
       "      <td>0.993151</td>\n",
       "      <td>0.993105</td>\n",
       "      <td>0.987937</td>\n",
       "      <td>0.998069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.994898</td>\n",
       "      <td>0.994878</td>\n",
       "      <td>0.997990</td>\n",
       "      <td>0.991889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.016792</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.996260</td>\n",
       "      <td>0.996257</td>\n",
       "      <td>0.994773</td>\n",
       "      <td>0.997683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.016592</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.995979</td>\n",
       "      <td>0.996138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.019206</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.995671</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.997185</td>\n",
       "      <td>0.994206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.020144</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.995674</td>\n",
       "      <td>0.995666</td>\n",
       "      <td>0.997587</td>\n",
       "      <td>0.993820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.019293</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.995864</td>\n",
       "      <td>0.995863</td>\n",
       "      <td>0.996381</td>\n",
       "      <td>0.995365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996061</td>\n",
       "      <td>0.996060</td>\n",
       "      <td>0.996783</td>\n",
       "      <td>0.995365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1899, training_loss=0.07372614171337817, metrics={'train_runtime': 836.8511, 'train_samples_per_second': 72.658, 'train_steps_per_second': 2.269, 'total_flos': 7993457212661760.0, 'train_loss': 0.07372614171337817, 'epoch': 2.997632202052092})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=your_path,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy='steps',\n",
    "    eval_steps=100,\n",
    "    learning_rate=2e-5,\n",
    "    save_steps=1000,\n",
    "    gradient_accumulation_steps=2\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_encoded['train'],\n",
    "    eval_dataset=dataset_encoded['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7L3GQsHPDRL"
   },
   "source": [
    "Once you're finito, you can evaluate the results, save your model and the state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:35:01.390858Z",
     "iopub.status.busy": "2024-08-05T19:35:01.390269Z",
     "iopub.status.idle": "2024-08-05T19:35:17.697506Z",
     "shell.execute_reply": "2024-08-05T19:35:17.696482Z",
     "shell.execute_reply.started": "2024-08-05T19:35:01.390832Z"
    },
    "id": "lCiYYKyqhFL0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='318' max='318' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [318/318 00:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.evaluate()\n",
    "trainer.save_model(your_path)\n",
    "trainer.save_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vim7CVwhPKY4"
   },
   "source": [
    "If you want to test it out, you can run the pipeline directly with the model. I just used some new example titles to see how it did."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:35:19.857124Z",
     "iopub.status.busy": "2024-08-05T19:35:19.856617Z",
     "iopub.status.idle": "2024-08-05T19:35:20.573531Z",
     "shell.execute_reply": "2024-08-05T19:35:20.572568Z",
     "shell.execute_reply.started": "2024-08-05T19:35:19.857104Z"
    },
    "id": "pTvsu7rOhYTL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "pipe = pipeline('text-classification', model='scenario_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:35:23.206495Z",
     "iopub.status.busy": "2024-08-05T19:35:23.205890Z",
     "iopub.status.idle": "2024-08-05T19:35:25.776713Z",
     "shell.execute_reply": "2024-08-05T19:35:25.774892Z",
     "shell.execute_reply.started": "2024-08-05T19:35:23.206472Z"
    },
    "id": "wmG1MgK1haml",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Sex up ur mobile with a FREE sexy pic of Aho! Just text BABE to 88600. Then every wk get a sexy celeb! PocketBabe.co.uk 4 more pics. 16 £3/wk 087016248\n",
      "Output: phishing\n",
      "Title: Pity.  Reading that woman's ad and knowing Rohit for years, they sound like a match made in heaven.  But why, oh, why, keep that shaved-head photo on prominent display???  There are lots of photos of Rohit looking rather dashing, and with the crucial hair feature enabled!R\n",
      "Output: benign\n"
     ]
    }
   ],
   "source": [
    "example_titles = [\n",
    "    \"Sex up ur mobile with a FREE sexy pic of Aho! Just text BABE to 88600. Then every wk get a sexy celeb! PocketBabe.co.uk 4 more pics. 16 \\u00a33/wk 087016248\",\n",
    "    \"Pity.  Reading that woman's ad and knowing Rohit for years, they sound like a match made in heaven.  But why, oh, why, keep that shaved-head photo on prominent display???  There are lots of photos of Rohit looking rather dashing, and with the crucial hair feature enabled!R\",\n",
    "]\n",
    "\n",
    "for title in example_titles:\n",
    "    result = pipe(title)\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Output: {result[0]['label']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bscp7lvwPW7N"
   },
   "source": [
    "If you're satisfied, you can log in to HuggingFace with a token (you'll find these in your account under Settings - make sure it has write access)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:36:36.211168Z",
     "iopub.status.busy": "2024-08-05T19:36:36.210600Z",
     "iopub.status.idle": "2024-08-05T19:36:37.099781Z",
     "shell.execute_reply": "2024-08-05T19:36:37.098177Z",
     "shell.execute_reply.started": "2024-08-05T19:36:36.211148Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token 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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P98pcG_LPhoV"
   },
   "source": [
    "Push the model with your new name for it. It usually just takes the name you set when you trained it so whatever you put here doesn't matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-05T19:36:39.584190Z",
     "iopub.status.busy": "2024-08-05T19:36:39.582821Z",
     "iopub.status.idle": "2024-08-05T19:37:36.336701Z",
     "shell.execute_reply": "2024-08-05T19:37:36.335314Z",
     "shell.execute_reply.started": "2024-08-05T19:36:39.584150Z"
    },
    "id": "pVE_898bhhTR",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b50988dc1e43be86ec9dac4f032cd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/16.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd88a9e1723d4ae8aa1257ef36f201f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d802243bdb474a86fd07c175c7d065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5a591f5a9484da318f4805110026b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7a05c13742402d80389d802861d9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf74833bff8a4a6580e1d7db0a3125e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/5.11k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/jordan2889/scenario_3/commit/2431ad2e38089e35a651368502c6e3005adebcd5', commit_message='jordan2889/scenario_3', commit_description='', oid='2431ad2e38089e35a651368502c6e3005adebcd5', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"jordan2889/scenario_3\")\n",
    "trainer.push_to_hub(\"jordan2889/scenario_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lUokttBHPvoc"
   },
   "source": [
    "Now, you're done. You got your text classifier."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN3C3XgYBmqGPgFOx823pPs",
   "gpuType": "L4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
